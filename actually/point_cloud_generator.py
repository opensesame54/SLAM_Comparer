import cv2
import numpy as np
import os
import open3d as o3d
import sys
import gc

# ----------------- CONFIGURATION -----------------
DATASET_BASE_PATH = "actually/rgbd_dataset_freiburg1_room" ### MODIFIED: Assuming 'actually' folder structure ###
ASSOCIATIONS_FILE = "associations.txt"
TRAJECTORY_FILE = "CameraTrajectory.txt" # Make sure this file is in your project_cv directory
OUTPUT_PLY_FILE = "room_point_cloud.ply"

# --- Process every Nth frame ---
FRAME_STRIDE = 3

# ---------- Camera intrinsics (TUM Freiburg1 dataset) ----------
o3d_intrinsics = o3d.camera.PinholeCameraIntrinsic(
    width=640,  
    height=480, 
    fx=517.3, 
    fy=516.5, 
    cx=318.6, 
    cy=255.3
)

# -----------------------------------------------------
# Utility Functions
# -----------------------------------------------------

### MODIFIED: Load associations including timestamps ###
def load_associations(base_path, file_path):
    """Loads associations (timestamp, rgb_path, depth_path) and sorts them."""
    full_path = os.path.join(base_path, file_path)
    pairs = []
    try:
        with open(full_path, "r") as f:
            for line in f:
                if line.startswith("#"): 
                    continue
                parts = line.strip().split()
                # Check for 4 parts (timestamp rgb_file timestamp depth_file)
                if len(parts) == 4:
                    timestamp = float(parts[0]) # Get the timestamp
                    rgb_file = os.path.join(base_path, parts[1])
                    depth_file = os.path.join(base_path, parts[3])
                    pairs.append((timestamp, rgb_file, depth_file)) # Store timestamp
                # Check for 8 parts if generated by the original associate.py
                elif len(parts) == 8:
                    timestamp = float(parts[0])
                    rgb_file = os.path.join(base_path, parts[1])
                    depth_file = os.path.join(base_path, parts[4]) # Depth file is at index 4
                    pairs.append((timestamp, rgb_file, depth_file))
                
    except FileNotFoundError:
        print(f"Error: Associations file not found at {full_path}.")
        sys.exit(1)
    
    # Sort pairs by timestamp
    pairs.sort()
    print(f"[INFO] Loaded {len(pairs)} image pairs from {full_path}")
    return pairs

### MODIFIED: Load poses from the 8-column TUM format ###
def load_poses_from_file(file_path):
    """
    Loads poses from a TUM-style trajectory file (timestamp tx ty tz qx qy qz qw).
    Converts the (tx, ty, tz, qx, qy, qz, qw) format into a 4x4 transformation matrix.
    Returns a dictionary mapping timestamps (as floats) to 4x4 pose matrices.
    """
    poses = {}  # Use a dictionary to map timestamp to pose
    try:
        with open(file_path, 'r') as f:
            for line in f:
                if line.startswith('#') or len(line.strip()) == 0:
                    continue
                
                parts = line.strip().split()
                
                if len(parts) == 8:
                    # File format: timestamp tx ty tz qx qy qz qw
                    timestamp = float(parts[0])
                    
                    translation = np.array([float(p) for p in parts[1:4]])
                    # Quaternion TUM format is (qx qy qz qw)
                    # Open3D expects (w, x, y, z) for get_rotation_matrix_from_quaternion
                    quaternion = np.array([
                        float(parts[7]),  # qw (w)
                        float(parts[4]),  # qx (x)
                        float(parts[5]),  # qy (y)
                        float(parts[6])   # qz (z)
                    ])
                    
                    pose_matrix = np.eye(4)
                    rotation_matrix = o3d.geometry.get_rotation_matrix_from_quaternion(quaternion)
                    pose_matrix[:3, :3] = rotation_matrix
                    pose_matrix[:3, 3] = translation
                    
                    poses[timestamp] = pose_matrix
                    
    except FileNotFoundError:
        print(f"Error: Trajectory file not found at '{file_path}'.")
        sys.exit(1)
        
    if not poses:
        print(f"[ERROR] Loaded 0 poses from {file_path}. Is the file empty or in the wrong format (should be 8 columns)?")
    else:
        print(f"[INFO] Loaded {len(poses)} poses from {file_path}")
        
    return poses

# -----------------------------------------------------
# Main 3D Point Cloud Generation
# -----------------------------------------------------

### MODIFIED: Function now takes poses_dict ###
def generate_and_visualize_point_cloud(pairs, poses_dict):
    
    final_pcd = o3d.geometry.PointCloud()
    
    if not poses_dict:
        print("Error: Could not load any poses. Please check the trajectory file.")
        return

    print(f"Starting 3D point cloud generation across {len(pairs)} frames (processing every {FRAME_STRIDE} frames)...")

    processed_frames = 0 # Counter for print statements

    for idx in range(0, len(pairs), FRAME_STRIDE):
        timestamp, rgb_path, depth_path = pairs[idx]

        ### MODIFIED: Find the closest pose in time, same as 2D script ###
        try:
            pose_timestamp = min(poses_dict.keys(), key=lambda k: abs(k - timestamp))
        except ValueError:
            print("Warning: Poses dictionary is empty.")
            continue # Skip frame if no poses loaded

        if abs(pose_timestamp - timestamp) > 0.02: # Check if pose is reasonably close in time
            # print(f"Warning: No close pose found for frame {idx} (timestamp {timestamp:.4f}, closest pose {pose_timestamp:.4f}). Skipping.")
            continue
            
        T_world_camera = poses_dict[pose_timestamp]
        ### END MODIFIED SECTION ###

        # 1. Load Data
        try:
            rgb_image = o3d.io.read_image(rgb_path)
            depth_image = o3d.io.read_image(depth_path)
        except Exception as e:
            print(f"Warning: Could not read frame {idx}, skipping. Error: {e}")
            continue
        
        # 2. Create RGBD Image
        rgbd_image = o3d.geometry.RGBDImage.create_from_tum_format(
            rgb_image, depth_image, convert_rgb_to_intensity=False
        )
        
        # 3. Generate Point Cloud from the single frame
        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(
            rgbd_image, 
            o3d_intrinsics
        )
        
        # 4. Transform into the global world frame
        pcd.transform(T_world_camera)
        
        # 5. Downsample before adding (helps manage memory)
        pcd_downsampled = pcd.voxel_down_sample(voxel_size=0.01) # 4cm voxel size
        
        # 6. Add to the final combined point cloud
        final_pcd += pcd_downsampled

        processed_frames += 1
        if processed_frames % 10 == 0:
             print(f"Processed {processed_frames} frames...")
        
        # Clean up memory
        del rgb_image, depth_image, rgbd_image, pcd, pcd_downsampled
        gc.collect()


    print(f"\n[INFO] Total points before final cleaning: {len(final_pcd.points)}")

    # Clean up any remaining noise with Statistical Outlier Removal
    print("[INFO] Removing statistical outliers (denoising)...")
    cl, ind = final_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
    final_pcd = final_pcd.select_by_index(ind)
    print(f"[INFO] Final point count after cleaning: {len(final_pcd.points)}")

    # Save and Visualize
    o3d.io.write_point_cloud(OUTPUT_PLY_FILE, final_pcd)
    print(f"\n[SUCCESS] Point cloud saved to {OUTPUT_PLY_FILE}")
    
    print("[INFO] Displaying final point cloud. Press 'q' to close.")
    o3d.visualization.draw_geometries([final_pcd], 
                                     window_name="3D Reconstruction")


if __name__ == '__main__':
    # Load associations (timestamp, rgb_path, depth_path)
    pairs = load_associations(DATASET_BASE_PATH, ASSOCIATIONS_FILE)
    # Load poses (timestamp -> 4x4 matrix)
    poses_dict = load_poses_from_file(TRAJECTORY_FILE) # Use the correct function

    if not pairs:
        print("Error: No image pairs were loaded. Check associations.txt.")
        sys.exit(1)
        
    if not poses_dict:
        print("Error: No poses were loaded. Check CameraTrajectory.txt.")
        sys.exit(1)
        
    generate_and_visualize_point_cloud(pairs, poses_dict) # Pass the dictionary